{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "1 - Sequence to Sequence Learning with Neural Networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasiliyeskin/crnn_seq2seq_ocr_pytorch/blob/master/train_for_image_to_formula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79WptoUd7asD",
        "outputId": "713068f2-2b3f-45cf-af51-4aa942feb1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/vasiliyeskin/crnn_seq2seq_ocr_pytorch.git"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'crnn_seq2seq_ocr_pytorch'...\n",
            "remote: Enumerating objects: 2454, done.\u001b[K\n",
            "remote: Counting objects: 100% (2454/2454), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1510/1510), done.\u001b[K\n",
            "remote: Total 2629 (delta 961), reused 2421 (delta 944), pack-reused 175\u001b[K\n",
            "Receiving objects: 100% (2629/2629), 54.00 MiB | 35.00 MiB/s, done.\n",
            "Resolving deltas: 100% (1053/1053), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITDpQNRCK6TX",
        "outputId": "9710fbbe-a41a-4dbf-a34d-31eff28cfd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd crnn_seq2seq_ocr_pytorch"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/crnn_seq2seq_ocr_pytorch/crnn_seq2seq_ocr_pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5yRjYgRLr1q",
        "outputId": "fd2e6e0a-8f41-4880-b193-bea24fb5c3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crnn\t      model\t\tsrc\t\t\t\t  train.py\n",
            "data\t      README.md\t\ttrain_for_image_to_formula.ipynb\n",
            "inference.py  requirements.txt\ttrain_im2latex.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G24wRwNKLuFI",
        "outputId": "b6e816fc-016b-4bdc-a269-a2e905d37435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_im2latex.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=32, decoder='', encoder='', eval_list='data/sample/validate_filter.lst', hidden_size=256, img_height=32, img_width=280, learning_rate=0.0001, max_width=71, model='./model/im2latex/', num_epochs=2, num_workers=4, random_sample=True, teaching_forcing_prob=0.5, train_list='data/sample/train_filter.lst')\n",
            "Encoder(\n",
            "  (cnn): CNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (10): ReLU(inplace=True)\n",
            "      (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (14): ReLU(inplace=True)\n",
            "      (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (16): ReLU(inplace=True)\n",
            "      (17): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "      (18): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "      (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (20): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (rnn): Sequential(\n",
            "    (0): BidirectionalLSTM(\n",
            "      (rnn): LSTM(512, 256, bidirectional=True)\n",
            "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
            "    )\n",
            "    (1): BidirectionalLSTM(\n",
            "      (rnn): LSTM(256, 256, bidirectional=True)\n",
            "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Decoder(\n",
            "  (decoder): AttnDecoderRNN(\n",
            "    (embedding): Embedding(255, 256)\n",
            "    (attn): Linear(in_features=512, out_features=71, bias=True)\n",
            "    (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (gru): GRU(256, 256)\n",
            "    (out): Linear(in_features=256, out_features=255, bias=True)\n",
            "  )\n",
            ")\n",
            "[Epoch 0/2] [Batch 0/29] Loss: 1972.2264404296875\n",
            "[Epoch 0/2] [Batch 1/29] Loss: 1617.7396240234375\n",
            "[Epoch 0/2] [Batch 2/29] Loss: 2240.85791015625\n",
            "[Epoch 0/2] [Batch 3/29] Loss: 2324.733642578125\n",
            "[Epoch 0/2] [Batch 4/29] Loss: 2194.48388671875\n",
            "[Epoch 0/2] [Batch 5/29] Loss: 1879.2296142578125\n",
            "[Epoch 0/2] [Batch 6/29] Loss: 1575.0413818359375\n",
            "[Epoch 0/2] [Batch 7/29] Loss: 2062.16552734375\n",
            "[Epoch 0/2] [Batch 8/29] Loss: 1994.0089111328125\n",
            "[Epoch 0/2] [Batch 9/29] Loss: 1937.1103515625\n",
            "[Epoch 0/2] [Batch 10/29] Loss: 1438.19580078125\n",
            "[Epoch 0/2] [Batch 11/29] Loss: 1238.8935546875\n",
            "[Epoch 0/2] [Batch 12/29] Loss: 1118.85302734375\n",
            "[Epoch 0/2] [Batch 13/29] Loss: 1117.4635009765625\n",
            "[Epoch 0/2] [Batch 14/29] Loss: 1016.3738403320312\n",
            "[Epoch 0/2] [Batch 15/29] Loss: 962.66162109375\n",
            "[Epoch 0/2] [Batch 16/29] Loss: 814.0892944335938\n",
            "[Epoch 0/2] [Batch 17/29] Loss: 778.064453125\n",
            "[Epoch 0/2] [Batch 18/29] Loss: 758.7821655273438\n",
            "[Epoch 0/2] [Batch 19/29] Loss: 642.94091796875\n",
            "[Epoch 0/2] [Batch 20/29] Loss: 598.292236328125\n",
            "[Epoch 0/2] [Batch 21/29] Loss: 779.961181640625\n",
            "[Epoch 0/2] [Batch 22/29] Loss: 650.1827392578125\n",
            "[Epoch 0/2] [Batch 23/29] Loss: 694.54345703125\n",
            "[Epoch 0/2] [Batch 24/29] Loss: 579.1719360351562\n",
            "[Epoch 0/2] [Batch 25/29] Loss: 776.0494995117188\n",
            "[Epoch 0/2] [Batch 26/29] Loss: 677.7644653320312\n",
            "[Epoch 0/2] [Batch 27/29] Loss: 761.2474365234375\n",
            "tensor([[[-0.6839,  0.7158,  0.5814,  ...,  0.4273,  0.6605,  0.6685]],\n",
            "\n",
            "        [[-0.8245,  0.8424,  0.6942,  ...,  0.5067,  0.7705,  0.7471]],\n",
            "\n",
            "        [[-0.9533,  0.9733,  0.8023,  ...,  0.5866,  0.8907,  0.8272]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4549,  1.3454,  1.1744,  ...,  0.8417,  1.4081,  1.0440]],\n",
            "\n",
            "        [[-1.2926,  1.1713,  1.0311,  ...,  0.7568,  1.2316,  0.8507]],\n",
            "\n",
            "        [[-1.0308,  0.8903,  0.7905,  ...,  0.6022,  0.9551,  0.5397]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward>)\n",
            "[Epoch 0/2] [Batch 28/29] Loss: 1284.7774658203125\n",
            "[Epoch 1/2] [Batch 0/29] Loss: 633.7377319335938\n",
            "[Epoch 1/2] [Batch 1/29] Loss: 706.7208862304688\n",
            "[Epoch 1/2] [Batch 2/29] Loss: 740.361328125\n",
            "[Epoch 1/2] [Batch 3/29] Loss: 566.149658203125\n",
            "[Epoch 1/2] [Batch 4/29] Loss: 705.9926147460938\n",
            "[Epoch 1/2] [Batch 5/29] Loss: 575.2929077148438\n",
            "[Epoch 1/2] [Batch 6/29] Loss: 600.4288330078125\n",
            "[Epoch 1/2] [Batch 7/29] Loss: 652.1700439453125\n",
            "[Epoch 1/2] [Batch 8/29] Loss: 679.1919555664062\n",
            "[Epoch 1/2] [Batch 9/29] Loss: 642.6710815429688\n",
            "[Epoch 1/2] [Batch 10/29] Loss: 753.6611938476562\n",
            "[Epoch 1/2] [Batch 11/29] Loss: 554.77294921875\n",
            "[Epoch 1/2] [Batch 12/29] Loss: 596.7062377929688\n",
            "[Epoch 1/2] [Batch 13/29] Loss: 627.6586303710938\n",
            "[Epoch 1/2] [Batch 14/29] Loss: 563.7324829101562\n",
            "[Epoch 1/2] [Batch 15/29] Loss: 581.5521850585938\n",
            "[Epoch 1/2] [Batch 16/29] Loss: 550.0347900390625\n",
            "[Epoch 1/2] [Batch 17/29] Loss: 616.1244506835938\n",
            "[Epoch 1/2] [Batch 18/29] Loss: 502.6729431152344\n",
            "[Epoch 1/2] [Batch 19/29] Loss: 566.8479614257812\n",
            "[Epoch 1/2] [Batch 20/29] Loss: 612.5769653320312\n",
            "[Epoch 1/2] [Batch 21/29] Loss: 640.2354736328125\n",
            "[Epoch 1/2] [Batch 22/29] Loss: 663.3460693359375\n",
            "[Epoch 1/2] [Batch 23/29] Loss: 511.4482421875\n",
            "[Epoch 1/2] [Batch 24/29] Loss: 641.2207641601562\n",
            "[Epoch 1/2] [Batch 25/29] Loss: 511.2425537109375\n",
            "[Epoch 1/2] [Batch 26/29] Loss: 506.1572570800781\n",
            "[Epoch 1/2] [Batch 27/29] Loss: 544.6786499023438\n",
            "tensor([[[-0.7152,  0.7212,  0.5757,  ...,  0.2748,  0.6065,  0.6629]],\n",
            "\n",
            "        [[-0.8534,  0.8284,  0.6802,  ...,  0.3213,  0.6996,  0.7544]],\n",
            "\n",
            "        [[-1.0051,  0.9560,  0.8060,  ...,  0.3746,  0.8118,  0.8620]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.9277,  1.6181,  1.4860,  ...,  0.7157,  1.6192,  1.3963]],\n",
            "\n",
            "        [[-1.6958,  1.3949,  1.2928,  ...,  0.6455,  1.4101,  1.1615]],\n",
            "\n",
            "        [[-1.3381,  1.0482,  0.9797,  ...,  0.5143,  1.0816,  0.7744]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward>)\n",
            "Traceback (most recent call last):\n",
            "  File \"train_im2latex.py\", line 242, in <module>\n",
            "    main()\n",
            "  File \"train_im2latex.py\", line 235, in main\n",
            "    train(image, text, encoder, decoder, criterion, train_loader, teach_forcing_prob=cfg.teaching_forcing_prob)\n",
            "  File \"train_im2latex.py\", line 102, in train\n",
            "    decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/crnn_seq2seq_ocr_pytorch/crnn_seq2seq_ocr_pytorch/crnn/seq2seq.py\", line 113, in forward\n",
            "    return self.decoder(input, hidden, encoder_outputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/crnn_seq2seq_ocr_pytorch/crnn_seq2seq_ocr_pytorch/crnn/seq2seq.py\", line 68, in forward\n",
            "    attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden[0]), 1)), dim=1)\n",
            "IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}